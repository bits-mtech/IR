{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "royal-performer",
   "metadata": {},
   "source": [
    "## IR Assignment Group-082\n",
    "\n",
    "## Group members\n",
    "\n",
    "<style>\n",
    "table {\n",
    "  font-family: arial, sans-serif;\n",
    "  border-collapse: collapse;\n",
    "  width: 100%;\n",
    "}\n",
    "\n",
    "td, th {\n",
    "  border: 1px solid #dddddd;\n",
    "  text-align: left;\n",
    "  padding: 8px;\n",
    "}\n",
    "\n",
    "tr:nth-child(even) {\n",
    "  background-color: #dddddd;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Full Name</th>\n",
    "    <th>BITS ID</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>T V Sriharini</td>\n",
    "    <td>2020fc04020@wilp.bits-pilani.ac.in</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Subodh Kant Mishra</td>\n",
    "    <td>2020fc04064@wilp.bits-pilani.ac.in</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Mriganka Shekhar Gayen</td>\n",
    "    <td>2020fc04069@wilp.bits-pilani.ac.in</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Given a Dataset collected from the Centre for Inventions and Scientific Information (\"CISI\") and consists of text data about 1,460 documents and 112 associated queries. Its purpose is to be used to build models of information retrieval where a given query will return a list of document IDs relevant to the query. The file \"CISI.REL\" contains the correct list (ie. \"gold standard\" or \"ground proof\") of query-document matching and your model can be compared against this \"gold standard\" to see how it has performed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-awareness",
   "metadata": {},
   "source": [
    "### 1. Load the data set and import necessary libraries (1 Marks)\n",
    "We import various packages used for text and general data processing\n",
    "* Pandas, Numpy, Skleaarn - For Data Processing\n",
    "* NLTK - Natural Language Tool Kit for Natural Language Processing\n",
    "* OS, functools - General Packages for Processing files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "balanced-evaluation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Library imports\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import os, glob, re, sys, random, unicodedata, collections\n",
    "from tqdm import tqdm\n",
    "from functools import reduce\n",
    "import nltk\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import RSLPStemmer\n",
    "from nltk.tokenize import sent_tokenize , word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-shield",
   "metadata": {},
   "source": [
    "### 1.1 Importing the files - All FIle\n",
    "\n",
    "We are importing the CISI.ALL file where we perform text processing such as removing newline characters, and '.' characters,\n",
    "and split the data into different variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "weighted-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Processing DOCUMENTS\n",
    "doc_set = {}\n",
    "doc_id = \"\"\n",
    "doc_text = \"\"\n",
    "with open('C://Users//HP//Downloads//CISI.ALL//CISI.ALL') as f:\n",
    "    lines = \"\"\n",
    "    for l in f.readlines():\n",
    "        lines += \"\\n\" + l.strip() if l.startswith(\".\") else \" \" + l.strip()\n",
    "    lines = lines.lstrip(\"\\n\").split(\"\\n\")\n",
    "doc_count = 0\n",
    "for l in lines:\n",
    "    if l.startswith(\".I\"):\n",
    "        doc_id = int(l.split(\" \")[1].strip())-1\n",
    "    elif l.startswith(\".X\"):\n",
    "        doc_set[doc_id] = doc_text.lstrip(\" \")\n",
    "        doc_id = \"\"\n",
    "        doc_text = \"\"\n",
    "    else:\n",
    "        doc_text += l.strip()[3:] + \" \" # The first 3 characters of a line can be ignored. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-mistake",
   "metadata": {},
   "source": [
    "### 1.2 Importing the files - Queries FIle\n",
    "\n",
    "We are importing the CISI.QRY file where we perform text processing such as removing newline characters, and '.' characters,\n",
    "and split the data into different variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "labeled-reaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Processing QUERIES\n",
    "with open('C://Users//HP//Downloads//CISI.QRY') as f:\n",
    "    lines = \"\"\n",
    "    for l in f.readlines():\n",
    "        lines += \"\\n\" + l.strip() if l.startswith(\".\") else \" \" + l.strip()\n",
    "    lines = lines.lstrip(\"\\n\").split(\"\\n\")\n",
    "    \n",
    "qry_set = {}\n",
    "qry_id = \"\"\n",
    "for l in lines:\n",
    "    if l.startswith(\".I\"):\n",
    "        qry_id = int(l.split(\" \")[1].strip()) -1\n",
    "    elif l.startswith(\".W\"):\n",
    "        qry_set[qry_id] = l.strip()[3:]\n",
    "        qry_id = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-comparative",
   "metadata": {},
   "source": [
    "### 1.3 Importing the files - Rel FIle\n",
    "\n",
    "We are importing the CISI.QREL file where we perform text processing such as removing newline characters, and '.' characters,\n",
    "and split the data into different variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "available-fraud",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Processing QRELS\n",
    "rel_set = {}\n",
    "with open('C://Users//HP//Downloads//CISI.REL') as f:\n",
    "    for l in f.readlines():\n",
    "        qry_id = int(l.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[0]) -1\n",
    "        doc_id = int(l.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[-1])-1\n",
    "        if qry_id in rel_set:\n",
    "            rel_set[qry_id].append(doc_id)\n",
    "        else:\n",
    "            rel_set[qry_id] = []\n",
    "            rel_set[qry_id].append(doc_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-accreditation",
   "metadata": {},
   "source": [
    "### 2.1 Extract features from text files. Each unique word in the document can be considered as a feature (1 Mark)\n",
    "\n",
    "We check the General statistics of the file provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "public-electron",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 1460 documents, 112 queries and 76 mappings from CISI dataset\n",
      "Average 40.97 and 1 min number of relevant documents by query \n",
      "Queries without relevant documents:  [ 35  37  39  46  47  50  52  58  59  62  63  67  69  71  72  73  74  76\n",
      "  77  79  82  84  85  86  87  88  90  92  93 102 104 105 106 107 109 111]\n"
     ]
    }
   ],
   "source": [
    "## Here we check some statistics and info of CISI dataset\n",
    "\n",
    "print('Read %s documents, %s queries and %s mappings from CISI dataset' % \n",
    "      (len(doc_set), len(qry_set), len(rel_set)))\n",
    "\n",
    "number_of_rel_docs = [len(value) for key, value in rel_set.items()]\n",
    "print('Average %.2f and %d min number of relevant documents by query ' % \n",
    "      (np.mean(number_of_rel_docs), np.min(number_of_rel_docs)))\n",
    "\n",
    "print('Queries without relevant documents: ', \n",
    "      np.setdiff1d(list(qry_set.keys()),list(rel_set.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "proper-kuwait",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID 14 ==> How much do information retrieval and dissemination systems, as well as automated libraries, cost? Are they worth it to the researcher and to industry?\n",
      "Documents relevants to Query ID 14 [17, 26, 35, 48, 55, 58, 66, 73, 82, 125, 157, 163, 166, 191, 213, 221, 222, 249, 280, 291, 294, 298, 306, 330, 335, 337, 347, 364, 365, 366, 367, 371, 380, 445, 457, 464, 465, 481, 489, 490, 494, 496, 506, 519, 527, 590, 593, 622, 628, 638, 689, 719, 722, 723, 726, 727, 730, 778, 821, 833, 838, 847, 848, 864, 871, 896, 1099, 1160, 1247, 1304, 1352, 1357, 1362, 1365, 1367, 1370, 1371, 1373, 1374, 1375, 1376, 1409]\n",
      "Document ID 48 ==> Adaptive Information Dissemination Sage, C.R. Anderson, R.R. Fitzwater, D.R. Computer dissemination of information offers significant advantages over manual dissemination because the computer can use strategies that are impractical and in some cases impossible for a human.. This paper describes the Ames Laboratory Selective Dissemination of Information system with emphasis on the effectiveness of user feedback.. The system will accept any document, abstract, keyword, etc., in a KWIC or Science Citation Index Source format.. User profiles consist of words or word clusters each with an initially assigned significance value.. These values are used in making the decision to notify a user that he may be interested in a particular document.. According to responses, the significance values are increased or decreased and quickly attain an equilibrium which accurately describes the user's interests.. The system is economical compared to other existing SDI systems and human intervention is negligible except for adding and deleting profile entries.. \n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "idx = random.sample(rel_set.keys(),1)[0]\n",
    "\n",
    "print('Query ID %s ==>' % idx, qry_set[idx])\n",
    "rel_docs = rel_set[idx]\n",
    "print('Documents relevants to Query ID %s' % idx, rel_docs)\n",
    "sample_document_idx = random.sample(rel_docs,1)[0]\n",
    "print('Document ID %s ==>' % sample_document_idx, doc_set[sample_document_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fourth-cliff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ==>  How much do information retrieval and dissemination systems, as well as automated libraries, cost? Are they worth it to the researcher and to industry? \n",
      "Relevant documents IDs: ==>  [17, 26, 35, 48, 55, 58, 66, 73, 82, 125, 157, 163, 166, 191, 213, 221, 222, 249, 280, 291, 294, 298, 306, 330, 335, 337, 347, 364, 365, 366, 367, 371, 380, 445, 457, 464, 465, 481, 489, 490, 494, 496, 506, 519, 527, 590, 593, 622, 628, 638, 689, 719, 722, 723, 726, 727, 730, 778, 821, 833, 838, 847, 848, 864, 871, 896, 1099, 1160, 1247, 1304, 1352, 1357, 1362, 1365, 1367, 1370, 1371, 1373, 1374, 1375, 1376, 1409]\n",
      "[13.84492303 12.72656528 17.02184487 ... 12.72737224 14.26660278\n",
      " 14.10298505] 1460 1460\n"
     ]
    }
   ],
   "source": [
    "query = qry_set[idx] #get query text\n",
    "rel_docs = rel_set[idx] #get relevant documents\n",
    "\n",
    "# Index all documents using BM25\n",
    "corpus = list(doc_set.values())\n",
    "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "# Process query and get scores for each indexed document using BM25\n",
    "tokenized_query = query.split(\" \")\n",
    "print('Query ==> ', query, '\\nRelevant documents IDs: ==> ', rel_docs)\n",
    "scores = bm25.get_scores(tokenized_query)\n",
    "print(scores, len(scores), len(doc_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "banned-alloy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.611111111111111"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Source: https://gist.github.com/bwhite/3726239\n",
    "def mean_reciprocal_rank(bool_results, k=10):\n",
    "    \"\"\"Score is reciprocal of the rank of the first relevant item\n",
    "    First element is 'rank 1'.  Relevance is binary (nonzero is relevant).\n",
    "    Example from http://en.wikipedia.org/wiki/Mean_reciprocal_rank\n",
    "    >>> rs = [[0, 0, 1], [0, 1, 0], [1, 0, 0]]\n",
    "    >>> mean_reciprocal_rank(rs)\n",
    "    0.61111111111111105\n",
    "\n",
    "    Args:\n",
    "        rs: Iterator of relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "    Returns:\n",
    "        Mean reciprocal rank\n",
    "    \"\"\"\n",
    "    bool_results = (np.atleast_1d(r[:k]).nonzero()[0] for r in bool_results)\n",
    "    return np.mean([1. / (r[0] + 1) if r.size else 0. for r in bool_results])\n",
    "\n",
    "mean_reciprocal_rank([[0, 0, 1], [0, 1, 0], [1, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dynamic-recipient",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 655  593  254  663  767  176  292  514  363  139   23  313 1026  460\n",
      " 1447 1236  825  326 1276   27]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "## Argsort gives the indexes of values in increasing order, so we input with the negative values of scores\n",
    "most_relevant_documents = np.argsort(-scores)\n",
    "\n",
    "print(most_relevant_documents[:20]) # printing first 20 most relevant results\n",
    "\n",
    "## Mask relevant documents with 0's and 1's according to query <-> document annotation\n",
    "masked_relevance_results = np.zeros(most_relevant_documents.shape)\n",
    "masked_relevance_results[rel_docs] = 1\n",
    "sorted_masked_relevance_results = np.take(masked_relevance_results, most_relevant_documents)\n",
    "\n",
    "print(sorted_masked_relevance_results[:20]) #printing first 20 results: 1 is relevant 0 isn't\n",
    "\n",
    "# Calculate MRR@10\n",
    "print(mean_reciprocal_rank([sorted_masked_relevance_results]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "brown-salvation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@10 0.3146\n"
     ]
    }
   ],
   "source": [
    "def results_from_query(qry_id, bm25):\n",
    "    \"\"\"Return an ordered array of relevant documents returned by query_id\n",
    "\n",
    "    Args:\n",
    "        qry_id (int): id of query on dataset\n",
    "        bm25 (object): indexed corpus\n",
    "\n",
    "    Returns:\n",
    "        boolean sorted relevance array of documents\n",
    "    \"\"\"    \n",
    "    query = qry_set[qry_id]\n",
    "    query = qry_set[qry_id]\n",
    "    rel_docs = []\n",
    "    if qry_id in rel_set:\n",
    "        rel_docs = rel_set[qry_id]\n",
    "    tokenized_query = query.split(\" \")\n",
    "    scores = bm25.get_scores(tokenized_query)\n",
    "    most_relevant_documents = np.argsort(-scores)\n",
    "    masked_relevance_results = np.zeros(most_relevant_documents.shape)\n",
    "  \n",
    "    masked_relevance_results[rel_docs] = 1\n",
    "    sorted_masked_relevance_results = np.take(masked_relevance_results, most_relevant_documents)\n",
    "    \n",
    "    return sorted_masked_relevance_results\n",
    "\n",
    "\n",
    "results = [results_from_query(qry_id, bm25) for qry_id in list(qry_set.keys())]\n",
    "print('MRR@10 %.4f' % mean_reciprocal_rank(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "rolled-ranking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instaciate objects from NLTK\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "radical-infection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_string(txt, remove_stop=True, do_stem=True, to_lower=True):\n",
    "    \"\"\"\n",
    "    Return a preprocessed tokenized text.\n",
    "    \n",
    "    Args:\n",
    "        txt (str): original text to process\n",
    "        remove_stop (boolean): to remove or not stop words (common words)\n",
    "        do_stem (boolean): to do or not stemming (suffixes and prefixes removal)\n",
    "        to_lower (boolean): remove or not capital letters.\n",
    "        \n",
    "    Returns:\n",
    "        Return a preprocessed tokenized text.\n",
    "    \"\"\"    \n",
    "    if to_lower:\n",
    "        txt = txt.lower()\n",
    "    tokens = nltk.tokenize.word_tokenize(txt)\n",
    "    \n",
    "    if remove_stop:\n",
    "        tokens = [tk for tk in tokens if tk not in stop_words]\n",
    "    if do_stem:\n",
    "        tokens = [stemmer.stem(tk) for tk in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "standard-words",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@10 0.4187\n"
     ]
    }
   ],
   "source": [
    "corpus = list(doc_set.values())\n",
    "# You may experiment with this trying to improve MRR@10\n",
    "remove_stop = True\n",
    "do_stem = True\n",
    "to_lower = True\n",
    "\n",
    "tokenized_corpus = [preprocess_string(doc, remove_stop, do_stem, to_lower) for doc in corpus]\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "def results_from_query_new(qry_id, bm25):\n",
    "    query = qry_set[qry_id]\n",
    "    rel_docs = []\n",
    "    if qry_id in rel_set:\n",
    "        rel_docs = rel_set[qry_id]\n",
    "    tokenized_query = preprocess_string(query, remove_stop, do_stem, to_lower)\n",
    "    scores = bm25.get_scores(tokenized_query)\n",
    "    most_relevant_documents = np.argsort(-scores)\n",
    "    masked_relevance_results = np.zeros(most_relevant_documents.shape)\n",
    "corpus = list(doc_set.values())\n",
    "# You may experiment with this trying to improve MRR@10\n",
    "remove_stop = True\n",
    "do_stem = True\n",
    "to_lower = True\n",
    "\n",
    "tokenized_corpus = [preprocess_string(doc, remove_stop, do_stem, to_lower) for doc in corpus]\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "def results_from_query_new(qry_id, bm25):\n",
    "    query = qry_set[qry_id]\n",
    "    rel_docs = []\n",
    "    if qry_id in rel_set:\n",
    "        rel_docs = rel_set[qry_id]\n",
    "    tokenized_query = preprocess_string(query, remove_stop, do_stem, to_lower)\n",
    "    scores = bm25.get_scores(tokenized_query)\n",
    "    most_relevant_documents = np.argsort(-scores)\n",
    "    masked_relevance_results = np.zeros(most_relevant_documents.shape)\n",
    "    masked_relevance_results[rel_docs] = 1\n",
    "    sorted_masked_relevance_results = np.take(masked_relevance_results, most_relevant_documents)\n",
    "    return sorted_masked_relevance_results\n",
    "\n",
    "\n",
    "results = [results_from_query_new(qry_id, bm25) for qry_id in list(qry_set.keys())]\n",
    "print('MRR@10 %.4f' % mean_reciprocal_rank(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-latino",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-workshop",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
